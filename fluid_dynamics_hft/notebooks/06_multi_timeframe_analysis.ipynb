{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Timeframe Fluid Dynamics Analysis\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction to Multi-Scale Analysis](#introduction)\n",
    "2. [Wavelet Transform for Market Flow](#wavelet-transform)\n",
    "3. [Scale-Dependent Pattern Recognition](#scale-patterns)\n",
    "4. [Cross-Scale Energy Transfer](#energy-transfer)\n",
    "5. [Temporal Coherence Analysis](#temporal-coherence)\n",
    "6. [Multi-Timeframe Trading Signals](#trading-signals)\n",
    "7. [Regime Persistence Across Scales](#regime-persistence)\n",
    "8. [Advanced Visualization](#visualization)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Multi-timeframe analysis in fluid dynamics markets examines how patterns and energy cascades across different temporal scales. This approach reveals:\n",
    "\n",
    "- **Scale-dependent patterns**: Different fluid dynamics patterns emerge at various time scales\n",
    "- **Energy cascade mechanisms**: How energy transfers from large to small scales\n",
    "- **Cross-scale correlations**: How patterns at one scale influence others\n",
    "- **Temporal coherence**: Persistence of fluid patterns across time scales\n",
    "\n",
    "### Key Concepts:\n",
    "- **Microscale (seconds)**: Individual order interactions, shock waves\n",
    "- **Mesoscale (minutes)**: Vortex formation, boundary layer dynamics\n",
    "- **Macroscale (hours/days)**: Large-scale circulation, regime changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal, ndimage\n",
    "from scipy.fft import fft2, ifft2, fftfreq\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import FastICA\n",
    "import pywt\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.patches import Rectangle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "print(\"Multi-Timeframe Analysis Environment Initialized\")\n",
    "print(\"Libraries loaded: NumPy, SciPy, Wavelets, Scikit-learn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavelet Transform for Market Flow\n",
    "\n",
    "### Continuous Wavelet Transform (CWT)\n",
    "\n",
    "The CWT decomposes market flow signals into time-frequency components:\n",
    "\n",
    "$$W(a,b) = \\frac{1}{\\sqrt{a}} \\int_{-\\infty}^{\\infty} f(t) \\psi^*\\left(\\frac{t-b}{a}\\right) dt$$\n",
    "\n",
    "Where:\n",
    "- $a$ = scale parameter (related to frequency)\n",
    "- $b$ = translation parameter (time)\n",
    "- $\\psi$ = mother wavelet function\n",
    "- $f(t)$ = market flow signal\n",
    "\n",
    "### Morlet Wavelet for Financial Analysis\n",
    "\n",
    "The complex Morlet wavelet is ideal for financial time series:\n",
    "$$\\psi(t) = \\pi^{-1/4} e^{i\\omega_0 t} e^{-t^2/2}$$\n",
    "\n",
    "It provides good time-frequency localization for market pattern detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class MultiTimeframeFluidAnalyzer:\n",
    "    \"\"\"\n",
    "    Advanced multi-timeframe analysis using wavelet transforms and fluid dynamics\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, sampling_rate=1000):\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.scales = np.logspace(0, 3, 50)  # 50 scales from 1 to 1000\n",
    "        self.wavelet = 'cmor1.5-1.0'  # Complex Morlet wavelet\n",
    "        \n",
    "    def generate_synthetic_market_data(self, length=2048):\n",
    "        \"\"\"\n",
    "        Generate synthetic multi-scale market flow data\n",
    "        \"\"\"\n",
    "        t = np.linspace(0, 10, length)\n",
    "        dt = t[1] - t[0]\n",
    "        \n",
    "        # Multi-scale components\n",
    "        # Macro trend (low frequency)\n",
    "        macro_trend = 2 * np.sin(0.5 * t) + 0.5 * np.sin(0.3 * t)\n",
    "        \n",
    "        # Meso patterns (medium frequency)\n",
    "        meso_pattern = np.sin(5 * t) * np.exp(-0.1 * (t - 5)**2)\n",
    "        \n",
    "        # Micro fluctuations (high frequency)\n",
    "        micro_noise = 0.3 * np.random.randn(length)\n",
    "        \n",
    "        # Market shocks (impulse responses)\n",
    "        shock_times = [2.5, 6.0, 8.5]\n",
    "        shocks = np.zeros(length)\n",
    "        for shock_time in shock_times:\n",
    "            shock_idx = int(shock_time / dt)\n",
    "            if shock_idx < length:\n",
    "                shock_width = 50\n",
    "                shock_indices = np.arange(max(0, shock_idx-shock_width//2), \n",
    "                                        min(length, shock_idx+shock_width//2))\n",
    "                shocks[shock_indices] += 2.0 * np.exp(-((shock_indices - shock_idx) / 20)**2)\n",
    "        \n",
    "        # Combine all components\n",
    "        market_flow = macro_trend + meso_pattern + micro_noise + shocks\n",
    "        \n",
    "        return {\n",
    "            'time': t,\n",
    "            'flow': market_flow,\n",
    "            'macro': macro_trend,\n",
    "            'meso': meso_pattern,\n",
    "            'micro': micro_noise,\n",
    "            'shocks': shocks\n",
    "        }\n",
    "    \n",
    "    def perform_cwt_analysis(self, signal):\n",
    "        \"\"\"\n",
    "        Perform Continuous Wavelet Transform analysis\n",
    "        \"\"\"\n",
    "        # Compute CWT\n",
    "        coefficients, frequencies = pywt.cwt(signal, self.scales, self.wavelet, \n",
    "                                           sampling_period=1/self.sampling_rate)\n",
    "        \n",
    "        # Convert scales to periods\n",
    "        periods = 1.0 / frequencies\n",
    "        \n",
    "        # Compute wavelet power spectrum\n",
    "        power = np.abs(coefficients)**2\n",
    "        \n",
    "        # Compute phase information\n",
    "        phase = np.angle(coefficients)\n",
    "        \n",
    "        # Compute instantaneous frequency\n",
    "        inst_freq = np.diff(np.unwrap(phase, axis=1), axis=1) / (2 * np.pi)\n",
    "        \n",
    "        return {\n",
    "            'coefficients': coefficients,\n",
    "            'power': power,\n",
    "            'phase': phase,\n",
    "            'frequencies': frequencies,\n",
    "            'periods': periods,\n",
    "            'instantaneous_frequency': inst_freq\n",
    "        }\n",
    "    \n",
    "    def detect_scale_dependent_patterns(self, cwt_result, threshold_percentile=90):\n",
    "        \"\"\"\n",
    "        Detect patterns at different time scales\n",
    "        \"\"\"\n",
    "        power = cwt_result['power']\n",
    "        periods = cwt_result['periods']\n",
    "        \n",
    "        # Define scale categories\n",
    "        micro_mask = periods < 0.1  # Very short term\n",
    "        meso_mask = (periods >= 0.1) & (periods < 1.0)  # Medium term\n",
    "        macro_mask = periods >= 1.0  # Long term\n",
    "        \n",
    "        # Compute scale-specific power\n",
    "        micro_power = np.mean(power[micro_mask, :], axis=0)\n",
    "        meso_power = np.mean(power[meso_mask, :], axis=0)\n",
    "        macro_power = np.mean(power[macro_mask, :], axis=0)\n",
    "        \n",
    "        # Detect high-activity regions\n",
    "        threshold = np.percentile(power, threshold_percentile)\n",
    "        \n",
    "        # Find scale-specific events\n",
    "        micro_events = micro_power > np.percentile(micro_power, threshold_percentile)\n",
    "        meso_events = meso_power > np.percentile(meso_power, threshold_percentile)\n",
    "        macro_events = macro_power > np.percentile(macro_power, threshold_percentile)\n",
    "        \n",
    "        return {\n",
    "            'micro_power': micro_power,\n",
    "            'meso_power': meso_power,\n",
    "            'macro_power': macro_power,\n",
    "            'micro_events': micro_events,\n",
    "            'meso_events': meso_events,\n",
    "            'macro_events': macro_events,\n",
    "            'scale_masks': {\n",
    "                'micro': micro_mask,\n",
    "                'meso': meso_mask,\n",
    "                'macro': macro_mask\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Initialize analyzer\n",
    "analyzer = MultiTimeframeFluidAnalyzer()\n",
    "\n",
    "# Generate synthetic market data\n",
    "market_data = analyzer.generate_synthetic_market_data(length=2048)\n",
    "\n",
    "print(f\"Generated synthetic market data with {len(market_data['time'])} time points\")\n",
    "print(f\"Time span: {market_data['time'][0]:.2f} to {market_data['time'][-1]:.2f}\")\n",
    "print(f\"Flow range: {np.min(market_data['flow']):.2f} to {np.max(market_data['flow']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Scale Energy Transfer Analysis\n",
    "\n",
    "### Energy Cascade Theory\n",
    "\n",
    "Energy cascade in financial markets shows how energy transfers between scales:\n",
    "\n",
    "$$\\frac{\\partial E(k)}{\\partial t} = T(k) - \\varepsilon(k) + F(k)$$\n",
    "\n",
    "Where:\n",
    "- $E(k)$ = energy at wavenumber $k$\n",
    "- $T(k)$ = energy transfer function\n",
    "- $\\varepsilon(k)$ = energy dissipation\n",
    "- $F(k)$ = external forcing\n",
    "\n",
    "### Wavelet-Based Energy Transfer\n",
    "\n",
    "Using wavelets, we can quantify energy transfer between scales through:\n",
    "- Scale-to-scale energy flux\n",
    "- Cross-scale phase relationships\n",
    "- Coherence analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_cross_scale_energy_transfer(cwt_result):\n",
    "    \"\"\"\n",
    "    Analyze energy transfer between different time scales\n",
    "    \"\"\"\n",
    "    power = cwt_result['power']\n",
    "    phase = cwt_result['phase']\n",
    "    periods = cwt_result['periods']\n",
    "    \n",
    "    n_scales, n_times = power.shape\n",
    "    \n",
    "    # Compute scale-to-scale energy flux\n",
    "    energy_flux = np.zeros((n_scales-1, n_times))\n",
    "    \n",
    "    for i in range(n_scales-1):\n",
    "        # Energy difference between adjacent scales\n",
    "        scale_diff = np.log(periods[i+1]) - np.log(periods[i])\n",
    "        power_gradient = (power[i+1, :] - power[i, :]) / scale_diff\n",
    "        \n",
    "        # Phase coherence between scales\n",
    "        phase_diff = np.angle(np.exp(1j * (phase[i+1, :] - phase[i, :])))\n",
    "        coherence = np.abs(np.mean(np.exp(1j * phase_diff)))\n",
    "        \n",
    "        # Energy flux incorporating phase relationships\n",
    "        energy_flux[i, :] = power_gradient * coherence\n",
    "    \n",
    "    # Compute cumulative energy transfer\n",
    "    cumulative_transfer = np.cumsum(energy_flux, axis=0)\n",
    "    \n",
    "    # Identify dominant energy pathways\n",
    "    flux_magnitude = np.abs(energy_flux)\n",
    "    dominant_transfers = flux_magnitude > np.percentile(flux_magnitude, 75)\n",
    "    \n",
    "    # Scale-averaged properties\n",
    "    upscale_transfer = np.mean(energy_flux[energy_flux > 0])  # Energy going to larger scales\n",
    "    downscale_transfer = np.mean(energy_flux[energy_flux < 0])  # Energy going to smaller scales\n",
    "    \n",
    "    return {\n",
    "        'energy_flux': energy_flux,\n",
    "        'cumulative_transfer': cumulative_transfer,\n",
    "        'dominant_transfers': dominant_transfers,\n",
    "        'upscale_transfer': upscale_transfer,\n",
    "        'downscale_transfer': downscale_transfer,\n",
    "        'net_transfer': upscale_transfer + downscale_transfer\n",
    "    }\n",
    "\n",
    "def compute_temporal_coherence(cwt_result, window_size=50):\n",
    "    \"\"\"\n",
    "    Compute temporal coherence of patterns across scales\n",
    "    \"\"\"\n",
    "    coefficients = cwt_result['coefficients']\n",
    "    n_scales, n_times = coefficients.shape\n",
    "    \n",
    "    # Sliding window coherence analysis\n",
    "    n_windows = n_times - window_size + 1\n",
    "    coherence_matrix = np.zeros((n_scales, n_windows))\n",
    "    \n",
    "    for i in range(n_windows):\n",
    "        window_coeffs = coefficients[:, i:i+window_size]\n",
    "        \n",
    "        # Compute local coherence for each scale\n",
    "        for scale in range(n_scales):\n",
    "            # Phase consistency within window\n",
    "            phases = np.angle(window_coeffs[scale, :])\n",
    "            phase_coherence = np.abs(np.mean(np.exp(1j * phases)))\n",
    "            coherence_matrix[scale, i] = phase_coherence\n",
    "    \n",
    "    # Compute cross-scale coherence\n",
    "    cross_scale_coherence = np.zeros((n_scales, n_scales))\n",
    "    for i in range(n_scales):\n",
    "        for j in range(n_scales):\n",
    "            if i != j:\n",
    "                # Correlation between coherence patterns\n",
    "                corr = np.corrcoef(coherence_matrix[i, :], coherence_matrix[j, :])[0, 1]\n",
    "                cross_scale_coherence[i, j] = corr\n",
    "    \n",
    "    return {\n",
    "        'temporal_coherence': coherence_matrix,\n",
    "        'cross_scale_coherence': cross_scale_coherence,\n",
    "        'mean_coherence_by_scale': np.mean(coherence_matrix, axis=1)\n",
    "    }\n",
    "\n",
    "# Perform CWT analysis on market flow\n",
    "cwt_result = analyzer.perform_cwt_analysis(market_data['flow'])\n",
    "\n",
    "# Detect scale-dependent patterns\n",
    "pattern_analysis = analyzer.detect_scale_dependent_patterns(cwt_result)\n",
    "\n",
    "# Analyze cross-scale energy transfer\n",
    "energy_transfer = analyze_cross_scale_energy_transfer(cwt_result)\n",
    "\n",
    "# Compute temporal coherence\n",
    "coherence_analysis = compute_temporal_coherence(cwt_result)\n",
    "\n",
    "print(\"Multi-scale Analysis Complete:\")\n",
    "print(f\"Upscale energy transfer: {energy_transfer['upscale_transfer']:.4f}\")\n",
    "print(f\"Downscale energy transfer: {energy_transfer['downscale_transfer']:.4f}\")\n",
    "print(f\"Net energy transfer: {energy_transfer['net_transfer']:.4f}\")\n",
    "print(f\"Micro-scale events detected: {np.sum(pattern_analysis['micro_events'])}\")\n",
    "print(f\"Meso-scale events detected: {np.sum(pattern_analysis['meso_events'])}\")\n",
    "print(f\"Macro-scale events detected: {np.sum(pattern_analysis['macro_events'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Timeframe Trading Signal Generation\n",
    "\n",
    "### Signal Synthesis Across Scales\n",
    "\n",
    "Effective trading signals combine information from multiple timeframes:\n",
    "\n",
    "$$S_{total}(t) = \\sum_{i} w_i \\cdot S_i(t) \\cdot C_i(t)$$\n",
    "\n",
    "Where:\n",
    "- $S_i(t)$ = signal from scale $i$\n",
    "- $w_i$ = weight for scale $i$\n",
    "- $C_i(t)$ = confidence measure for scale $i$\n",
    "\n",
    "### Adaptive Weighting Strategy\n",
    "\n",
    "Weights are dynamically adjusted based on:\n",
    "- Scale-specific pattern strength\n",
    "- Historical performance\n",
    "- Market regime characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class MultiTimeframeSignalGenerator:\n",
    "    \"\"\"\n",
    "    Generate trading signals from multi-timeframe fluid dynamics analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.scale_weights = {\n",
    "            'micro': 0.2,   # Short-term signals\n",
    "            'meso': 0.5,    # Medium-term signals\n",
    "            'macro': 0.3    # Long-term signals\n",
    "        }\n",
    "        \n",
    "    def generate_scale_signals(self, pattern_analysis, cwt_result):\n",
    "        \"\"\"\n",
    "        Generate signals for each time scale\n",
    "        \"\"\"\n",
    "        power = cwt_result['power']\n",
    "        phase = cwt_result['phase']\n",
    "        periods = cwt_result['periods']\n",
    "        \n",
    "        signals = {}\n",
    "        \n",
    "        for scale_name, mask in pattern_analysis['scale_masks'].items():\n",
    "            if np.any(mask):\n",
    "                # Average power and phase for this scale\n",
    "                scale_power = np.mean(power[mask, :], axis=0)\n",
    "                scale_phase = np.mean(phase[mask, :], axis=0)\n",
    "                \n",
    "                # Signal strength based on power\n",
    "                power_signal = (scale_power - np.mean(scale_power)) / np.std(scale_power)\n",
    "                \n",
    "                # Directional signal based on phase derivatives\n",
    "                phase_derivative = np.gradient(scale_phase)\n",
    "                direction_signal = np.tanh(phase_derivative)  # Normalize to [-1, 1]\n",
    "                \n",
    "                # Combined signal\n",
    "                combined_signal = power_signal * direction_signal\n",
    "                \n",
    "                # Confidence based on power concentration\n",
    "                confidence = scale_power / (np.mean(power) + 1e-8)\n",
    "                confidence = np.clip(confidence, 0, 1)\n",
    "                \n",
    "                signals[scale_name] = {\n",
    "                    'signal': combined_signal,\n",
    "                    'power_signal': power_signal,\n",
    "                    'direction_signal': direction_signal,\n",
    "                    'confidence': confidence\n",
    "                }\n",
    "        \n",
    "        return signals\n",
    "    \n",
    "    def synthesize_final_signal(self, scale_signals, energy_transfer):\n",
    "        \"\"\"\n",
    "        Combine signals from all scales with adaptive weighting\n",
    "        \"\"\"\n",
    "        # Adjust weights based on energy transfer patterns\n",
    "        transfer_factor = abs(energy_transfer['net_transfer'])\n",
    "        \n",
    "        # Adaptive weights (favor scales with strong energy transfer)\n",
    "        adaptive_weights = self.scale_weights.copy()\n",
    "        if transfer_factor > 0.1:  # Significant energy transfer\n",
    "            if energy_transfer['upscale_transfer'] > abs(energy_transfer['downscale_transfer']):\n",
    "                # Energy moving to larger scales - favor macro\n",
    "                adaptive_weights['macro'] *= 1.5\n",
    "                adaptive_weights['micro'] *= 0.7\n",
    "            else:\n",
    "                # Energy moving to smaller scales - favor micro\n",
    "                adaptive_weights['micro'] *= 1.5\n",
    "                adaptive_weights['macro'] *= 0.7\n",
    "        \n",
    "        # Normalize weights\n",
    "        total_weight = sum(adaptive_weights.values())\n",
    "        adaptive_weights = {k: v/total_weight for k, v in adaptive_weights.items()}\n",
    "        \n",
    "        # Combine signals\n",
    "        final_signal = np.zeros_like(scale_signals['micro']['signal'])\n",
    "        total_confidence = np.zeros_like(final_signal)\n",
    "        \n",
    "        for scale_name, weight in adaptive_weights.items():\n",
    "            if scale_name in scale_signals:\n",
    "                scale_data = scale_signals[scale_name]\n",
    "                weighted_signal = weight * scale_data['signal'] * scale_data['confidence']\n",
    "                final_signal += weighted_signal\n",
    "                total_confidence += weight * scale_data['confidence']\n",
    "        \n",
    "        # Normalize by total confidence\n",
    "        final_signal = np.divide(final_signal, total_confidence, \n",
    "                               out=np.zeros_like(final_signal), where=total_confidence!=0)\n",
    "        \n",
    "        return {\n",
    "            'signal': final_signal,\n",
    "            'confidence': total_confidence,\n",
    "            'adaptive_weights': adaptive_weights\n",
    "        }\n",
    "    \n",
    "    def generate_trading_decisions(self, final_signal, threshold=0.5):\n",
    "        \"\"\"\n",
    "        Convert signals to trading decisions\n",
    "        \"\"\"\n",
    "        signal_values = final_signal['signal']\n",
    "        confidence = final_signal['confidence']\n",
    "        \n",
    "        # Trading decisions based on signal strength and confidence\n",
    "        buy_signals = (signal_values > threshold) & (confidence > 0.3)\n",
    "        sell_signals = (signal_values < -threshold) & (confidence > 0.3)\n",
    "        hold_signals = ~(buy_signals | sell_signals)\n",
    "        \n",
    "        # Position sizing based on confidence\n",
    "        position_size = confidence * np.abs(signal_values)\n",
    "        position_size = np.clip(position_size, 0, 1)  # Normalize to [0, 1]\n",
    "        \n",
    "        return {\n",
    "            'buy_signals': buy_signals,\n",
    "            'sell_signals': sell_signals,\n",
    "            'hold_signals': hold_signals,\n",
    "            'position_size': position_size,\n",
    "            'signal_strength': np.abs(signal_values)\n",
    "        }\n",
    "\n",
    "# Initialize signal generator\n",
    "signal_generator = MultiTimeframeSignalGenerator()\n",
    "\n",
    "# Generate scale-specific signals\n",
    "scale_signals = signal_generator.generate_scale_signals(pattern_analysis, cwt_result)\n",
    "\n",
    "# Synthesize final signal\n",
    "final_signal = signal_generator.synthesize_final_signal(scale_signals, energy_transfer)\n",
    "\n",
    "# Generate trading decisions\n",
    "trading_decisions = signal_generator.generate_trading_decisions(final_signal)\n",
    "\n",
    "print(\"Trading Signal Generation Complete:\")\n",
    "print(f\"Adaptive weights: {final_signal['adaptive_weights']}\")\n",
    "print(f\"Buy signals: {np.sum(trading_decisions['buy_signals'])}\")\n",
    "print(f\"Sell signals: {np.sum(trading_decisions['sell_signals'])}\")\n",
    "print(f\"Hold signals: {np.sum(trading_decisions['hold_signals'])}\")\n",
    "print(f\"Average position size: {np.mean(trading_decisions['position_size']):.3f}\")\n",
    "print(f\"Signal strength range: {np.min(trading_decisions['signal_strength']):.3f} to {np.max(trading_decisions['signal_strength']):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Multi-Timeframe Visualization\n",
    "\n",
    "This section creates comprehensive visualizations showing how fluid dynamics patterns emerge and evolve across different time scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create comprehensive multi-timeframe visualization\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "gs = GridSpec(4, 4, figure=fig, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Main title\n",
    "fig.suptitle('Multi-Timeframe Fluid Dynamics Analysis', fontsize=18, fontweight='bold')\n",
    "\n",
    "# 1. Original signal components (top row)\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "t = market_data['time']\n",
    "ax1.plot(t, market_data['macro'], label='Macro (Trend)', alpha=0.8, linewidth=2)\n",
    "ax1.plot(t, market_data['meso'], label='Meso (Patterns)', alpha=0.8, linewidth=2)\n",
    "ax1.plot(t, market_data['micro'], label='Micro (Noise)', alpha=0.6, linewidth=1)\n",
    "ax1.plot(t, market_data['shocks'], label='Shocks', alpha=0.8, linewidth=2)\n",
    "ax1.plot(t, market_data['flow'], 'k-', label='Combined Flow', alpha=0.9, linewidth=2)\n",
    "ax1.set_title('Market Flow Components Across Time Scales')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Flow Magnitude')\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Wavelet power spectrum (second row, left)\n",
    "ax2 = fig.add_subplot(gs[1, :2])\n",
    "power_db = 10 * np.log10(cwt_result['power'] + 1e-8)  # Convert to dB\n",
    "im1 = ax2.imshow(power_db, aspect='auto', origin='lower', cmap='jet',\n",
    "                extent=[t[0], t[-1], 0, len(cwt_result['periods'])])\n",
    "ax2.set_title('Wavelet Power Spectrum (Time-Scale Analysis)')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Scale Index')\n",
    "plt.colorbar(im1, ax=ax2, label='Power (dB)')\n",
    "\n",
    "# Add scale annotations\n",
    "scale_indices = [0, len(cwt_result['periods'])//3, 2*len(cwt_result['periods'])//3, len(cwt_result['periods'])-1]\n",
    "scale_labels = ['Micro', 'Meso', 'Macro', 'Trend']\n",
    "ax2.set_yticks(scale_indices)\n",
    "ax2.set_yticklabels(scale_labels)\n",
    "\n",
    "# 3. Energy transfer (second row, right)\n",
    "ax3 = fig.add_subplot(gs[1, 2:])\n",
    "im2 = ax3.imshow(energy_transfer['energy_flux'], aspect='auto', origin='lower', \n",
    "                cmap='RdBu_r', extent=[t[0], t[-1], 0, energy_transfer['energy_flux'].shape[0]])\n",
    "ax3.set_title('Cross-Scale Energy Transfer')\n",
    "ax3.set_xlabel('Time')\n",
    "ax3.set_ylabel('Scale Transfer Index')\n",
    "plt.colorbar(im2, ax=ax3, label='Energy Flux')\n",
    "\n",
    "# 4. Scale-specific signals (third row)\n",
    "ax4 = fig.add_subplot(gs[2, 0])\n",
    "if 'micro' in scale_signals:\n",
    "    ax4.plot(t, scale_signals['micro']['signal'], 'b-', alpha=0.8)\n",
    "    ax4.fill_between(t, 0, scale_signals['micro']['confidence'], alpha=0.3)\n",
    "ax4.set_title('Micro-Scale Signals')\n",
    "ax4.set_xlabel('Time')\n",
    "ax4.set_ylabel('Signal')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "ax5 = fig.add_subplot(gs[2, 1])\n",
    "if 'meso' in scale_signals:\n",
    "    ax5.plot(t, scale_signals['meso']['signal'], 'g-', alpha=0.8)\n",
    "    ax5.fill_between(t, 0, scale_signals['meso']['confidence'], alpha=0.3)\n",
    "ax5.set_title('Meso-Scale Signals')\n",
    "ax5.set_xlabel('Time')\n",
    "ax5.set_ylabel('Signal')\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "ax6 = fig.add_subplot(gs[2, 2])\n",
    "if 'macro' in scale_signals:\n",
    "    ax6.plot(t, scale_signals['macro']['signal'], 'r-', alpha=0.8)\n",
    "    ax6.fill_between(t, 0, scale_signals['macro']['confidence'], alpha=0.3)\n",
    "ax6.set_title('Macro-Scale Signals')\n",
    "ax6.set_xlabel('Time')\n",
    "ax6.set_ylabel('Signal')\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Final trading signal (third row, right)\n",
    "ax7 = fig.add_subplot(gs[2, 3])\n",
    "ax7.plot(t, final_signal['signal'], 'k-', linewidth=2, label='Final Signal')\n",
    "ax7.fill_between(t, 0, final_signal['confidence'], alpha=0.3, label='Confidence')\n",
    "\n",
    "# Mark trading decisions\n",
    "buy_times = t[trading_decisions['buy_signals']]\n",
    "sell_times = t[trading_decisions['sell_signals']]\n",
    "\n",
    "if len(buy_times) > 0:\n",
    "    ax7.scatter(buy_times, final_signal['signal'][trading_decisions['buy_signals']], \n",
    "               c='green', marker='^', s=50, label='Buy', zorder=5)\n",
    "if len(sell_times) > 0:\n",
    "    ax7.scatter(sell_times, final_signal['signal'][trading_decisions['sell_signals']], \n",
    "               c='red', marker='v', s=50, label='Sell', zorder=5)\n",
    "\n",
    "ax7.set_title('Final Trading Signal')\n",
    "ax7.set_xlabel('Time')\n",
    "ax7.set_ylabel('Signal')\n",
    "ax7.legend()\n",
    "ax7.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Cross-scale coherence matrix (bottom row, left)\n",
    "ax8 = fig.add_subplot(gs[3, :2])\n",
    "coherence_matrix = coherence_analysis['cross_scale_coherence']\n",
    "im3 = ax8.imshow(coherence_matrix, cmap='viridis', aspect='auto')\n",
    "ax8.set_title('Cross-Scale Coherence Matrix')\n",
    "ax8.set_xlabel('Scale Index')\n",
    "ax8.set_ylabel('Scale Index')\n",
    "plt.colorbar(im3, ax=ax8, label='Coherence')\n",
    "\n",
    "# 7. Performance summary (bottom row, right)\n",
    "ax9 = fig.add_subplot(gs[3, 2:])\n",
    "ax9.axis('off')\n",
    "\n",
    "# Summary statistics\n",
    "summary_text = f\"\"\"\n",
    "MULTI-TIMEFRAME ANALYSIS SUMMARY\n",
    "\n",
    "Scale Distribution:\n",
    "• Micro events: {np.sum(pattern_analysis['micro_events'])}\n",
    "• Meso events: {np.sum(pattern_analysis['meso_events'])}\n",
    "• Macro events: {np.sum(pattern_analysis['macro_events'])}\n",
    "\n",
    "Energy Transfer:\n",
    "• Upscale: {energy_transfer['upscale_transfer']:.4f}\n",
    "• Downscale: {energy_transfer['downscale_transfer']:.4f}\n",
    "• Net transfer: {energy_transfer['net_transfer']:.4f}\n",
    "\n",
    "Trading Signals:\n",
    "• Buy signals: {np.sum(trading_decisions['buy_signals'])}\n",
    "• Sell signals: {np.sum(trading_decisions['sell_signals'])}\n",
    "• Hold periods: {np.sum(trading_decisions['hold_signals'])}\n",
    "\n",
    "Adaptive Weights:\n",
    "• Micro: {final_signal['adaptive_weights']['micro']:.3f}\n",
    "• Meso: {final_signal['adaptive_weights']['meso']:.3f}\n",
    "• Macro: {final_signal['adaptive_weights']['macro']:.3f}\n",
    "\n",
    "Signal Quality:\n",
    "• Mean confidence: {np.mean(final_signal['confidence']):.3f}\n",
    "• Signal range: [{np.min(final_signal['signal']):.3f}, {np.max(final_signal['signal']):.3f}]\n",
    "• Position sizing: {np.mean(trading_decisions['position_size']):.3f} avg\n",
    "\n",
    "TRADING IMPLICATIONS:\n",
    "• {'Strong trend following regime' if energy_transfer['upscale_transfer'] > 0.01 else 'Choppy/ranging market' if abs(energy_transfer['net_transfer']) < 0.005 else 'Mixed regime with volatility clustering'}\n",
    "• {'High confidence signals' if np.mean(final_signal['confidence']) > 0.5 else 'Moderate confidence' if np.mean(final_signal['confidence']) > 0.3 else 'Low confidence - reduce position sizes'}\n",
    "\"\"\"\n",
    "\n",
    "ax9.text(0.05, 0.95, summary_text, transform=ax9.transAxes, \n",
    "         fontsize=11, verticalalignment='top', fontfamily='monospace',\n",
    "         bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MULTI-TIMEFRAME FLUID DYNAMICS ANALYSIS COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Analysis processed {len(market_data['time'])} time points across {len(cwt_result['periods'])} scales\")\n",
    "print(f\"Energy cascade direction: {'Upscale dominant' if energy_transfer['upscale_transfer'] > abs(energy_transfer['downscale_transfer']) else 'Downscale dominant'}\")\n",
    "print(f\"Signal generation resulted in {np.sum(trading_decisions['buy_signals']) + np.sum(trading_decisions['sell_signals'])} trading opportunities\")\n",
    "print(f\"Average signal confidence: {np.mean(final_signal['confidence']):.1%}\")\n",
    "print(\"\\nThis analysis enables:\")\n",
    "print(\"• Scale-aware pattern recognition\")\n",
    "print(\"• Energy cascade-based regime detection\")\n",
    "print(\"• Multi-timeframe signal synthesis\")\n",
    "print(\"• Adaptive position sizing\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}