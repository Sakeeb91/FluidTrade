{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fluid Dynamics-Based Risk Management Strategies\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction to Fluid Risk Models](#introduction)\n",
    "2. [Turbulence-Based Risk Metrics](#turbulence-risk)\n",
    "3. [Vorticity Risk Assessment](#vorticity-risk)\n",
    "4. [Energy Dissipation and Drawdown](#energy-dissipation)\n",
    "5. [Dynamic Position Sizing](#position-sizing)\n",
    "6. [Portfolio Flow Correlation](#portfolio-flow)\n",
    "7. [Stress Testing with Fluid Scenarios](#stress-testing)\n",
    "8. [Risk-Adjusted Performance Metrics](#performance-metrics)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Traditional risk management relies on statistical measures like volatility and VaR. Fluid dynamics provides a richer framework for understanding market risk through:\n",
    "\n",
    "- **Turbulence intensity**: Measure of market chaos and unpredictability\n",
    "- **Vorticity patterns**: Early warning signals for trend reversals\n",
    "- **Energy dissipation**: Rate of capital erosion during adverse conditions\n",
    "- **Flow coherence**: Correlation structure across assets and timeframes\n",
    "- **Regime stability**: Persistence and transition probabilities\n",
    "\n",
    "### Key Advantages:\n",
    "- **Forward-looking**: Anticipates risk before it materializes\n",
    "- **Multi-dimensional**: Captures complex risk interactions\n",
    "- **Dynamic**: Adapts to changing market conditions\n",
    "- **Regime-aware**: Risk metrics adjust based on market state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats, signal\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.covariance import LedoitWolf\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Ellipse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "print(\"Fluid Dynamics Risk Management Environment Initialized\")\n",
    "print(\"Advanced risk models ready for deployment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turbulence-Based Risk Metrics\n",
    "\n",
    "### Turbulent Kinetic Energy (TKE)\n",
    "\n",
    "TKE measures the intensity of market turbulence:\n",
    "$$TKE = \\frac{1}{2}\\langle u'^2 + v'^2 \\rangle$$\n",
    "\n",
    "Where $u'$ and $v'$ are velocity fluctuations from the mean flow.\n",
    "\n",
    "### Reynolds Stress Tensor\n",
    "\n",
    "Captures correlations between velocity components:\n",
    "$$R_{ij} = \\langle u'_i u'_j \\rangle$$\n",
    "\n",
    "### Turbulence Intensity\n",
    "\n",
    "Normalized measure of turbulence:\n",
    "$$I = \\frac{\\sqrt{TKE}}{|\\vec{U}|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class FluidRiskManager:\n",
    "    \"\"\"\n",
    "    Comprehensive risk management using fluid dynamics principles\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lookback_window=252):\n",
    "        self.lookback_window = lookback_window\n",
    "        self.risk_metrics = {}\n",
    "        self.position_limits = {}\n",
    "        self.stress_scenarios = {}\n",
    "        \n",
    "    def generate_market_data(self, n_assets=5, n_periods=1000):\n",
    "        \"\"\"\n",
    "        Generate synthetic multi-asset market data with regime changes\n",
    "        \"\"\"\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        # Create correlation matrix\n",
    "        correlation_base = np.random.uniform(0.1, 0.7, (n_assets, n_assets))\n",
    "        correlation_matrix = (correlation_base + correlation_base.T) / 2\n",
    "        np.fill_diagonal(correlation_matrix, 1.0)\n",
    "        \n",
    "        # Generate different market regimes\n",
    "        regime_changes = [0, 250, 500, 750, 1000]\n",
    "        regimes = ['normal', 'volatile', 'trending', 'crisis']\n",
    "        \n",
    "        returns_data = []\n",
    "        prices_data = []\n",
    "        regime_labels = []\n",
    "        \n",
    "        for i in range(len(regime_changes)-1):\n",
    "            start_idx = regime_changes[i]\n",
    "            end_idx = regime_changes[i+1]\n",
    "            period_length = end_idx - start_idx\n",
    "            \n",
    "            regime = regimes[i % len(regimes)]\n",
    "            \n",
    "            # Regime-specific parameters\n",
    "            if regime == 'normal':\n",
    "                volatility = np.random.uniform(0.15, 0.25, n_assets)\n",
    "                mean_return = np.random.uniform(-0.001, 0.002, n_assets)\n",
    "            elif regime == 'volatile':\n",
    "                volatility = np.random.uniform(0.4, 0.8, n_assets)\n",
    "                mean_return = np.random.uniform(-0.002, 0.001, n_assets)\n",
    "            elif regime == 'trending':\n",
    "                volatility = np.random.uniform(0.1, 0.2, n_assets)\n",
    "                mean_return = np.random.uniform(0.001, 0.005, n_assets)\n",
    "            else:  # crisis\n",
    "                volatility = np.random.uniform(0.6, 1.2, n_assets)\n",
    "                mean_return = np.random.uniform(-0.01, -0.002, n_assets)\n",
    "                # Increase correlations during crisis\n",
    "                correlation_matrix = np.maximum(correlation_matrix, 0.8)\n",
    "                np.fill_diagonal(correlation_matrix, 1.0)\n",
    "            \n",
    "            # Generate correlated returns\n",
    "            L = np.linalg.cholesky(correlation_matrix)\n",
    "            uncorr_returns = np.random.normal(0, 1, (period_length, n_assets))\n",
    "            corr_returns = uncorr_returns @ L.T\n",
    "            \n",
    "            # Scale by volatility and add mean\n",
    "            scaled_returns = corr_returns * volatility + mean_return\n",
    "            \n",
    "            returns_data.append(scaled_returns)\n",
    "            regime_labels.extend([regime] * period_length)\n",
    "        \n",
    "        # Combine all periods\n",
    "        returns = np.vstack(returns_data)\n",
    "        \n",
    "        # Generate prices from returns\n",
    "        prices = np.zeros_like(returns)\n",
    "        prices[0] = 100.0  # Initial price\n",
    "        for t in range(1, len(returns)):\n",
    "            prices[t] = prices[t-1] * (1 + returns[t])\n",
    "        \n",
    "        # Create timestamps\n",
    "        timestamps = pd.date_range('2023-01-01', periods=n_periods, freq='D')\n",
    "        \n",
    "        return {\n",
    "            'returns': pd.DataFrame(returns, index=timestamps, \n",
    "                                  columns=[f'Asset_{i+1}' for i in range(n_assets)]),\n",
    "            'prices': pd.DataFrame(prices, index=timestamps,\n",
    "                                 columns=[f'Asset_{i+1}' for i in range(n_assets)]),\n",
    "            'regimes': pd.Series(regime_labels, index=timestamps, name='regime')\n",
    "        }\n",
    "    \n",
    "    def compute_turbulence_metrics(self, returns_df):\n",
    "        \"\"\"\n",
    "        Compute fluid dynamics-based turbulence metrics\n",
    "        \"\"\"\n",
    "        returns = returns_df.values\n",
    "        n_periods, n_assets = returns.shape\n",
    "        \n",
    "        # Compute velocity components (price momentum)\n",
    "        velocity_x = np.gradient(returns, axis=0)  # Time derivative\n",
    "        velocity_y = np.gradient(returns, axis=1)  # Cross-asset derivative\n",
    "        \n",
    "        # Mean flow\n",
    "        mean_vx = np.mean(velocity_x, axis=0)\n",
    "        mean_vy = np.mean(velocity_y, axis=0)\n",
    "        \n",
    "        # Velocity fluctuations\n",
    "        vx_prime = velocity_x - mean_vx\n",
    "        vy_prime = velocity_y - mean_vy\n",
    "        \n",
    "        # Turbulent Kinetic Energy\n",
    "        tke = 0.5 * (vx_prime**2 + vy_prime**2)\n",
    "        \n",
    "        # Reynolds stress tensor components\n",
    "        reynolds_uu = np.mean(vx_prime**2, axis=0)\n",
    "        reynolds_vv = np.mean(vy_prime**2, axis=0)\n",
    "        reynolds_uv = np.mean(vx_prime * vy_prime, axis=0)\n",
    "        \n",
    "        # Turbulence intensity\n",
    "        mean_velocity_mag = np.sqrt(mean_vx**2 + mean_vy**2)\n",
    "        turbulence_intensity = np.sqrt(2 * np.mean(tke, axis=0) / 3) / (mean_velocity_mag + 1e-8)\n",
    "        \n",
    "        # Energy dissipation rate (proxy)\n",
    "        velocity_gradients = np.gradient(velocity_x, axis=0)**2 + np.gradient(velocity_y, axis=0)**2\n",
    "        dissipation_rate = np.mean(velocity_gradients, axis=0)\n",
    "        \n",
    "        return {\n",
    "            'tke': tke,\n",
    "            'tke_mean': np.mean(tke, axis=0),\n",
    "            'reynolds_stress': {\n",
    "                'uu': reynolds_uu,\n",
    "                'vv': reynolds_vv,\n",
    "                'uv': reynolds_uv\n",
    "            },\n",
    "            'turbulence_intensity': turbulence_intensity,\n",
    "            'dissipation_rate': dissipation_rate,\n",
    "            'velocity_x': velocity_x,\n",
    "            'velocity_y': velocity_y\n",
    "        }\n",
    "    \n",
    "    def compute_vorticity_risk(self, turbulence_metrics):\n",
    "        \"\"\"\n",
    "        Compute vorticity-based risk measures\n",
    "        \"\"\"\n",
    "        vx = turbulence_metrics['velocity_x']\n",
    "        vy = turbulence_metrics['velocity_y']\n",
    "        \n",
    "        # Compute vorticity (curl of velocity field)\n",
    "        dvx_dy = np.gradient(vx, axis=1)\n",
    "        dvy_dx = np.gradient(vy, axis=0)\n",
    "        vorticity = dvy_dx - dvx_dy\n",
    "        \n",
    "        # Vorticity-based risk metrics\n",
    "        vorticity_magnitude = np.abs(vorticity)\n",
    "        mean_vorticity = np.mean(vorticity, axis=0)\n",
    "        vorticity_volatility = np.std(vorticity, axis=0)\n",
    "        \n",
    "        # Circulation strength (integral of vorticity)\n",
    "        circulation = np.sum(vorticity, axis=0)\n",
    "        \n",
    "        # Vortex identification (Q-criterion)\n",
    "        dvx_dx = np.gradient(vx, axis=0)\n",
    "        dvy_dy = np.gradient(vy, axis=1)\n",
    "        \n",
    "        # Strain rate and rotation rate\n",
    "        strain_rate = 0.5 * ((dvx_dx - dvy_dy)**2 + (dvx_dy + dvy_dx)**2)\n",
    "        rotation_rate = 0.5 * (dvy_dx - dvx_dy)**2\n",
    "        \n",
    "        # Q-criterion: Q > 0 indicates vortex regions\n",
    "        Q_criterion = 0.5 * (rotation_rate - strain_rate)\n",
    "        \n",
    "        return {\n",
    "            'vorticity': vorticity,\n",
    "            'vorticity_magnitude': vorticity_magnitude,\n",
    "            'mean_vorticity': mean_vorticity,\n",
    "            'vorticity_volatility': vorticity_volatility,\n",
    "            'circulation': circulation,\n",
    "            'Q_criterion': Q_criterion,\n",
    "            'vortex_strength': np.mean(Q_criterion[Q_criterion > 0], axis=0) if np.any(Q_criterion > 0) else np.zeros(Q_criterion.shape[1])\n",
    "        }\n",
    "    \n",
    "    def dynamic_position_sizing(self, turbulence_metrics, vorticity_metrics, base_position=1.0):\n",
    "        \"\"\"\n",
    "        Dynamic position sizing based on fluid dynamics risk measures\n",
    "        \"\"\"\n",
    "        # Risk scaling factors\n",
    "        tke_factor = 1.0 / (1.0 + turbulence_metrics['tke_mean'])\n",
    "        turbulence_factor = 1.0 / (1.0 + turbulence_metrics['turbulence_intensity'])\n",
    "        vorticity_factor = 1.0 / (1.0 + np.abs(vorticity_metrics['mean_vorticity']))\n",
    "        dissipation_factor = 1.0 / (1.0 + turbulence_metrics['dissipation_rate'])\n",
    "        \n",
    "        # Combined risk adjustment\n",
    "        risk_weights = [0.3, 0.3, 0.2, 0.2]  # Weights for each factor\n",
    "        combined_factor = (risk_weights[0] * tke_factor + \n",
    "                          risk_weights[1] * turbulence_factor +\n",
    "                          risk_weights[2] * vorticity_factor +\n",
    "                          risk_weights[3] * dissipation_factor)\n",
    "        \n",
    "        # Apply minimum and maximum position limits\n",
    "        position_sizes = base_position * combined_factor\n",
    "        position_sizes = np.clip(position_sizes, 0.1, 2.0)  # 10% minimum, 200% maximum\n",
    "        \n",
    "        return {\n",
    "            'position_sizes': position_sizes,\n",
    "            'tke_factor': tke_factor,\n",
    "            'turbulence_factor': turbulence_factor,\n",
    "            'vorticity_factor': vorticity_factor,\n",
    "            'dissipation_factor': dissipation_factor,\n",
    "            'combined_factor': combined_factor\n",
    "        }\n",
    "\n",
    "# Initialize risk manager\n",
    "risk_manager = FluidRiskManager()\n",
    "\n",
    "# Generate sample market data\n",
    "market_data = risk_manager.generate_market_data(n_assets=5, n_periods=1000)\n",
    "\n",
    "print(\"Sample market data generated:\")\n",
    "print(f\"Assets: {market_data['returns'].shape[1]}\")\n",
    "print(f\"Time periods: {market_data['returns'].shape[0]}\")\n",
    "print(f\"Date range: {market_data['returns'].index[0]} to {market_data['returns'].index[-1]}\")\n",
    "print(f\"Regimes: {market_data['regimes'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio Flow Correlation and Risk Decomposition\n",
    "\n",
    "### Flow-Based Portfolio Risk\n",
    "\n",
    "Traditional portfolio risk: $\\sigma_p^2 = w^T \\Sigma w$\n",
    "\n",
    "Fluid dynamics enhancement:\n",
    "$$\\sigma_{fluid}^2 = w^T (\\Sigma + R_{turb} + \\Lambda_{vort}) w$$\n",
    "\n",
    "Where:\n",
    "- $R_{turb}$ = turbulence-induced risk matrix\n",
    "- $\\Lambda_{vort}$ = vorticity correlation matrix\n",
    "\n",
    "### Cross-Asset Flow Analysis\n",
    "\n",
    "Examines how fluid patterns propagate across different assets in the portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compute fluid dynamics risk metrics\n",
    "turbulence_metrics = risk_manager.compute_turbulence_metrics(market_data['returns'])\n",
    "vorticity_metrics = risk_manager.compute_vorticity_risk(turbulence_metrics)\n",
    "position_sizing = risk_manager.dynamic_position_sizing(turbulence_metrics, vorticity_metrics)\n",
    "\n",
    "# Advanced risk analysis\n",
    "def compute_portfolio_fluid_risk(returns_df, weights, turbulence_metrics, vorticity_metrics):\n",
    "    \"\"\"\n",
    "    Compute portfolio risk incorporating fluid dynamics effects\n",
    "    \"\"\"\n",
    "    returns = returns_df.values\n",
    "    n_assets = len(weights)\n",
    "    \n",
    "    # Traditional covariance matrix\n",
    "    cov_matrix = np.cov(returns.T)\n",
    "    \n",
    "    # Turbulence-enhanced covariance\n",
    "    tke_matrix = np.outer(turbulence_metrics['tke_mean'], turbulence_metrics['tke_mean'])\n",
    "    turbulence_cov = cov_matrix * (1 + 0.5 * tke_matrix)\n",
    "    \n",
    "    # Vorticity correlation matrix\n",
    "    vorticity_corr = np.corrcoef(vorticity_metrics['vorticity'].T)\n",
    "    vorticity_risk = 0.1 * vorticity_corr * np.outer(np.abs(vorticity_metrics['mean_vorticity']), \n",
    "                                                     np.abs(vorticity_metrics['mean_vorticity']))\n",
    "    \n",
    "    # Combined fluid risk matrix\n",
    "    fluid_cov = turbulence_cov + vorticity_risk\n",
    "    \n",
    "    # Portfolio risks\n",
    "    traditional_risk = np.sqrt(weights.T @ cov_matrix @ weights)\n",
    "    fluid_risk = np.sqrt(weights.T @ fluid_cov @ weights)\n",
    "    \n",
    "    return {\n",
    "        'traditional_risk': traditional_risk,\n",
    "        'fluid_risk': fluid_risk,\n",
    "        'risk_enhancement': fluid_risk / traditional_risk,\n",
    "        'cov_matrix': cov_matrix,\n",
    "        'fluid_cov_matrix': fluid_cov,\n",
    "        'turbulence_contribution': np.sqrt(weights.T @ turbulence_cov @ weights),\n",
    "        'vorticity_contribution': np.sqrt(weights.T @ (cov_matrix + vorticity_risk) @ weights)\n",
    "    }\n",
    "\n",
    "def stress_test_fluid_scenarios(returns_df, weights, n_scenarios=1000):\n",
    "    \"\"\"\n",
    "    Stress test portfolio under extreme fluid dynamics scenarios\n",
    "    \"\"\"\n",
    "    returns = returns_df.values\n",
    "    n_periods, n_assets = returns.shape\n",
    "    \n",
    "    scenarios = []\n",
    "    \n",
    "    for _ in range(n_scenarios):\n",
    "        # Generate extreme fluid scenario\n",
    "        scenario_type = np.random.choice(['turbulence_spike', 'vortex_formation', 'regime_shock', 'correlation_break'])\n",
    "        \n",
    "        if scenario_type == 'turbulence_spike':\n",
    "            # Sudden increase in market turbulence\n",
    "            volatility_multiplier = np.random.uniform(2, 5)\n",
    "            scenario_returns = returns[-30:] * volatility_multiplier\n",
    "        \n",
    "        elif scenario_type == 'vortex_formation':\n",
    "            # Trend reversal scenario\n",
    "            reversal_strength = np.random.uniform(0.5, 2.0)\n",
    "            scenario_returns = -returns[-30:] * reversal_strength\n",
    "        \n",
    "        elif scenario_type == 'regime_shock':\n",
    "            # Sudden regime change\n",
    "            shock_returns = np.random.normal(-0.05, 0.1, (30, n_assets))\n",
    "            scenario_returns = shock_returns\n",
    "        \n",
    "        else:  # correlation_break\n",
    "            # Correlation structure breaks down\n",
    "            uncorr_returns = np.random.normal(0, np.std(returns, axis=0), (30, n_assets))\n",
    "            scenario_returns = uncorr_returns\n",
    "        \n",
    "        # Compute scenario portfolio return\n",
    "        portfolio_returns = scenario_returns @ weights\n",
    "        cumulative_return = np.prod(1 + portfolio_returns) - 1\n",
    "        max_drawdown = np.min(np.cumprod(1 + portfolio_returns)) - 1\n",
    "        \n",
    "        scenarios.append({\n",
    "            'type': scenario_type,\n",
    "            'cumulative_return': cumulative_return,\n",
    "            'max_drawdown': max_drawdown,\n",
    "            'volatility': np.std(portfolio_returns)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(scenarios)\n",
    "\n",
    "# Example portfolio weights (equal weight)\n",
    "n_assets = market_data['returns'].shape[1]\n",
    "equal_weights = np.ones(n_assets) / n_assets\n",
    "\n",
    "# Risk-adjusted weights using fluid dynamics\n",
    "risk_adjusted_weights = position_sizing['position_sizes'] / np.sum(position_sizing['position_sizes'])\n",
    "\n",
    "# Compute portfolio risks\n",
    "equal_weight_risk = compute_portfolio_fluid_risk(market_data['returns'], equal_weights, \n",
    "                                                turbulence_metrics, vorticity_metrics)\n",
    "risk_adjusted_risk = compute_portfolio_fluid_risk(market_data['returns'], risk_adjusted_weights,\n",
    "                                                 turbulence_metrics, vorticity_metrics)\n",
    "\n",
    "# Stress testing\n",
    "stress_results = stress_test_fluid_scenarios(market_data['returns'], equal_weights, n_scenarios=500)\n",
    "\n",
    "print(\"Portfolio Risk Analysis:\")\n",
    "print(f\"\\nEqual Weight Portfolio:\")\n",
    "print(f\"Traditional Risk: {equal_weight_risk['traditional_risk']:.4f}\")\n",
    "print(f\"Fluid-Enhanced Risk: {equal_weight_risk['fluid_risk']:.4f}\")\n",
    "print(f\"Risk Enhancement Factor: {equal_weight_risk['risk_enhancement']:.2f}x\")\n",
    "\n",
    "print(f\"\\nRisk-Adjusted Portfolio:\")\n",
    "print(f\"Traditional Risk: {risk_adjusted_risk['traditional_risk']:.4f}\")\n",
    "print(f\"Fluid-Enhanced Risk: {risk_adjusted_risk['fluid_risk']:.4f}\")\n",
    "print(f\"Risk Enhancement Factor: {risk_adjusted_risk['risk_enhancement']:.2f}x\")\n",
    "\n",
    "print(f\"\\nStress Test Results:\")\n",
    "print(f\"Worst case return: {stress_results['cumulative_return'].min():.2%}\")\n",
    "print(f\"Maximum drawdown: {stress_results['max_drawdown'].min():.2%}\")\n",
    "print(f\"95% VaR: {stress_results['cumulative_return'].quantile(0.05):.2%}\")\n",
    "print(f\"Expected shortfall: {stress_results['cumulative_return'][stress_results['cumulative_return'] <= stress_results['cumulative_return'].quantile(0.05)].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk-Adjusted Performance Metrics\n",
    "\n",
    "### Fluid Sharpe Ratio\n",
    "\n",
    "Enhanced Sharpe ratio incorporating turbulence effects:\n",
    "$$Sharpe_{fluid} = \\frac{\\mu_p - r_f}{\\sigma_{fluid}}$$\n",
    "\n",
    "### Turbulence-Adjusted Returns\n",
    "\n",
    "$$R_{adj} = R_{raw} \\cdot (1 - \\alpha \\cdot TKE)$$\n",
    "\n",
    "### Vorticity Risk Premium\n",
    "\n",
    "Additional return required to compensate for vorticity-induced risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create comprehensive risk management visualization\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 14))\n",
    "fig.suptitle('Fluid Dynamics Risk Management Dashboard', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Turbulent Kinetic Energy over time (top left)\n",
    "ax1 = axes[0, 0]\n",
    "tke_timeline = np.mean(turbulence_metrics['tke'], axis=1)\n",
    "ax1.plot(market_data['returns'].index, tke_timeline, 'b-', alpha=0.7, linewidth=1.5)\n",
    "ax1.fill_between(market_data['returns'].index, 0, tke_timeline, alpha=0.3)\n",
    "ax1.set_title('Turbulent Kinetic Energy')\n",
    "ax1.set_ylabel('TKE')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Color by regime\n",
    "regime_colors = {'normal': 'green', 'volatile': 'orange', 'trending': 'blue', 'crisis': 'red'}\n",
    "for regime in regime_colors:\n",
    "    mask = market_data['regimes'] == regime\n",
    "    if mask.any():\n",
    "        ax1.scatter(market_data['returns'].index[mask], tke_timeline[mask], \n",
    "                   c=regime_colors[regime], s=10, alpha=0.6, label=regime)\n",
    "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# 2. Vorticity magnitude (top center)\n",
    "ax2 = axes[0, 1]\n",
    "vorticity_mag_timeline = np.mean(vorticity_metrics['vorticity_magnitude'], axis=1)\n",
    "ax2.plot(market_data['returns'].index, vorticity_mag_timeline, 'r-', alpha=0.7, linewidth=1.5)\n",
    "ax2.axhline(y=np.mean(vorticity_mag_timeline), color='black', linestyle='--', alpha=0.5, label='Mean')\n",
    "ax2.set_title('Vorticity Magnitude')\n",
    "ax2.set_ylabel('|Vorticity|')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Dynamic position sizing (top right)\n",
    "ax3 = axes[0, 2]\n",
    "asset_names = market_data['returns'].columns\n",
    "x_pos = np.arange(len(asset_names))\n",
    "bars = ax3.bar(x_pos, position_sizing['position_sizes'], alpha=0.7, \n",
    "               color=sns.color_palette(\"viridis\", len(asset_names)))\n",
    "ax3.axhline(y=1.0, color='red', linestyle='--', alpha=0.7, label='Base Position')\n",
    "ax3.set_title('Dynamic Position Sizing')\n",
    "ax3.set_xlabel('Assets')\n",
    "ax3.set_ylabel('Position Size Multiplier')\n",
    "ax3.set_xticks(x_pos)\n",
    "ax3.set_xticklabels(asset_names, rotation=45)\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{height:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 4. Risk decomposition (middle left)\n",
    "ax4 = axes[1, 0]\n",
    "risk_components = ['Traditional', 'Turbulence', 'Vorticity', 'Combined']\n",
    "risk_values = [\n",
    "    equal_weight_risk['traditional_risk'],\n",
    "    equal_weight_risk['turbulence_contribution'],\n",
    "    equal_weight_risk['vorticity_contribution'],\n",
    "    equal_weight_risk['fluid_risk']\n",
    "]\n",
    "colors = ['blue', 'orange', 'green', 'red']\n",
    "bars = ax4.bar(risk_components, risk_values, color=colors, alpha=0.7)\n",
    "ax4.set_title('Risk Decomposition')\n",
    "ax4.set_ylabel('Portfolio Risk')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, value in zip(bars, risk_values):\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.001,\n",
    "             f'{value:.4f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 5. Stress test results (middle center)\n",
    "ax5 = axes[1, 1]\n",
    "stress_results['cumulative_return'].hist(bins=30, alpha=0.7, ax=ax5, color='darkred')\n",
    "ax5.axvline(x=stress_results['cumulative_return'].quantile(0.05), color='red', \n",
    "           linestyle='--', linewidth=2, label='5% VaR')\n",
    "ax5.axvline(x=stress_results['cumulative_return'].mean(), color='blue', \n",
    "           linestyle='-', linewidth=2, label='Mean')\n",
    "ax5.set_title('Stress Test Distribution')\n",
    "ax5.set_xlabel('Cumulative Return')\n",
    "ax5.set_ylabel('Frequency')\n",
    "ax5.legend()\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Correlation heatmap (middle right)\n",
    "ax6 = axes[1, 2]\n",
    "corr_matrix = np.corrcoef(vorticity_metrics['vorticity'].T)\n",
    "im = ax6.imshow(corr_matrix, cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "ax6.set_title('Vorticity Correlation Matrix')\n",
    "ax6.set_xticks(range(len(asset_names)))\n",
    "ax6.set_yticks(range(len(asset_names)))\n",
    "ax6.set_xticklabels(asset_names, rotation=45)\n",
    "ax6.set_yticklabels(asset_names)\n",
    "plt.colorbar(im, ax=ax6)\n",
    "\n",
    "# Add correlation values\n",
    "for i in range(len(asset_names)):\n",
    "    for j in range(len(asset_names)):\n",
    "        ax6.text(j, i, f'{corr_matrix[i, j]:.2f}', ha='center', va='center',\n",
    "                color='white' if abs(corr_matrix[i, j]) > 0.5 else 'black', fontsize=8)\n",
    "\n",
    "# 7. Regime analysis (bottom left)\n",
    "ax7 = axes[2, 0]\n",
    "regime_risk = market_data['regimes'].value_counts()\n",
    "wedges, texts, autotexts = ax7.pie(regime_risk.values, labels=regime_risk.index, \n",
    "                                  autopct='%1.1f%%', startangle=90)\n",
    "ax7.set_title('Market Regime Distribution')\n",
    "\n",
    "# 8. Risk factors comparison (bottom center)\n",
    "ax8 = axes[2, 1]\n",
    "factors = ['TKE', 'Turbulence', 'Vorticity', 'Dissipation']\n",
    "factor_values = [\n",
    "    np.mean(position_sizing['tke_factor']),\n",
    "    np.mean(position_sizing['turbulence_factor']),\n",
    "    np.mean(position_sizing['vorticity_factor']),\n",
    "    np.mean(position_sizing['dissipation_factor'])\n",
    "]\n",
    "bars = ax8.barh(factors, factor_values, color=['red', 'orange', 'green', 'blue'], alpha=0.7)\n",
    "ax8.set_title('Risk Factor Contributions')\n",
    "ax8.set_xlabel('Factor Value (lower = higher risk)')\n",
    "ax8.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, value) in enumerate(zip(bars, factor_values)):\n",
    "    ax8.text(value + 0.01, bar.get_y() + bar.get_height()/2.,\n",
    "             f'{value:.3f}', ha='left', va='center', fontsize=9)\n",
    "\n",
    "# 9. Performance summary (bottom right)\n",
    "ax9 = axes[2, 2]\n",
    "ax9.axis('off')\n",
    "\n",
    "# Summary statistics\n",
    "portfolio_returns = market_data['returns'] @ equal_weights\n",
    "sharpe_ratio = portfolio_returns.mean() / portfolio_returns.std() * np.sqrt(252)\n",
    "max_dd = (portfolio_returns.cumsum() - portfolio_returns.cumsum().expanding().max()).min()\n",
    "calmar_ratio = portfolio_returns.mean() * 252 / abs(max_dd)\n",
    "\n",
    "summary_text = f\"\"\"\n",
    "RISK MANAGEMENT SUMMARY\n",
    "\n",
    "Portfolio Metrics:\n",
    "â€¢ Traditional Risk: {equal_weight_risk['traditional_risk']:.4f}\n",
    "â€¢ Fluid-Enhanced Risk: {equal_weight_risk['fluid_risk']:.4f}\n",
    "â€¢ Risk Enhancement: {equal_weight_risk['risk_enhancement']:.2f}x\n",
    "â€¢ Sharpe Ratio: {sharpe_ratio:.3f}\n",
    "â€¢ Calmar Ratio: {calmar_ratio:.3f}\n",
    "\n",
    "Risk Factors:\n",
    "â€¢ Mean TKE: {np.mean(turbulence_metrics['tke_mean']):.4f}\n",
    "â€¢ Mean Turbulence: {np.mean(turbulence_metrics['turbulence_intensity']):.3f}\n",
    "â€¢ Mean |Vorticity|: {np.mean(np.abs(vorticity_metrics['mean_vorticity'])):.4f}\n",
    "â€¢ Dissipation Rate: {np.mean(turbulence_metrics['dissipation_rate']):.4f}\n",
    "\n",
    "Stress Testing:\n",
    "â€¢ 5% VaR: {stress_results['cumulative_return'].quantile(0.05):.2%}\n",
    "â€¢ Expected Shortfall: {stress_results['cumulative_return'][stress_results['cumulative_return'] <= stress_results['cumulative_return'].quantile(0.05)].mean():.2%}\n",
    "â€¢ Worst Case: {stress_results['cumulative_return'].min():.2%}\n",
    "â€¢ Max Drawdown: {stress_results['max_drawdown'].min():.2%}\n",
    "\n",
    "Position Sizing:\n",
    "â€¢ Min Position: {position_sizing['position_sizes'].min():.2f}x\n",
    "â€¢ Max Position: {position_sizing['position_sizes'].max():.2f}x\n",
    "â€¢ Avg Position: {position_sizing['position_sizes'].mean():.2f}x\n",
    "\n",
    "Status: {'ðŸŸ¢ LOW RISK' if equal_weight_risk['risk_enhancement'] < 1.2 else 'ðŸŸ¡ MODERATE RISK' if equal_weight_risk['risk_enhancement'] < 1.5 else 'ðŸ”´ HIGH RISK'}\n",
    "\"\"\"\n",
    "\n",
    "ax9.text(0.05, 0.95, summary_text, transform=ax9.transAxes, \n",
    "         fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "         bbox=dict(boxstyle='round,pad=0.5', facecolor='lightcyan', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FLUID DYNAMICS RISK MANAGEMENT ANALYSIS COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Risk enhancement factor: {equal_weight_risk['risk_enhancement']:.2f}x traditional risk\")\n",
    "print(f\"Dynamic position adjustments range: {position_sizing['position_sizes'].min():.2f}x to {position_sizing['position_sizes'].max():.2f}x\")\n",
    "print(f\"Stress test scenarios evaluated: {len(stress_results)}\")\n",
    "print(f\"Worst-case portfolio loss: {stress_results['cumulative_return'].min():.2%}\")\n",
    "print(\"\\nKey Risk Management Features:\")\n",
    "print(\"â€¢ Turbulence-based risk metrics\")\n",
    "print(\"â€¢ Vorticity-driven position sizing\")\n",
    "print(\"â€¢ Multi-scenario stress testing\")\n",
    "print(\"â€¢ Real-time risk monitoring\")\n",
    "print(\"â€¢ Regime-aware risk models\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}